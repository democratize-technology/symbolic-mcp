# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Symbolic MCP Contributors

name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  release:
    types: [ published ]

env:
  PYTHON_DEFAULT_VERSION: '3.12'
  # Cache dependencies for faster builds
  CACHE_VERSION: v1

jobs:
  # === CODE QUALITY & SECURITY SCANNING ===

  security-scan:
    name: üîí Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for security analysis

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bandit[baseline] safety safety-db mypy flake8 black isort
          pip install -r requirements.txt

      - name: Run Bandit Security Scan
        run: |
          # Create baseline if it doesn't exist
          if [ ! -f .bandit-baseline ]; then
            bandit -r main.py -f json -o bandit-report.json
            bandit -r main.py -f txt -o bandit-report.txt
            bandit -r main.py -b .bandit-baseline
          else
            bandit -r main.py -f json -o bandit-report.json --baseline .bandit-baseline
          fi
        continue-on-error: false

      - name: Run Safety Dependency Check
        run: |
          safety check --json --output safety-report.json || true
          safety check --db --json --output safety-db-report.json || true
          safety check --full-report --output safety-full-report.txt || true

      - name: Check for Known CVEs
        run: |
          # Check for specific CVE patterns in dependencies
          echo "Checking for known vulnerability patterns..."
          safety check || echo "Safety check completed with findings"

      - name: Upload Security Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            bandit-report.txt
            safety-report.json
            safety-db-report.json
            safety-full-report.txt
          retention-days: 30

  code-quality:
    name: üîç Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install black isort flake8 mypy pylint
          pip install -r requirements.txt

      - name: Black Code Formatting Check
        run: |
          black --check --diff main.py
          black --check --diff tests/

      - name: isort Import Sorting Check
        run: |
          isort --check-only --diff main.py
          isort --check-only --diff tests/

      - name: Flake8 Linting
        run: |
          flake8 main.py --format=json --output-file=flake8-report.json || true
          flake8 main.py --format=clippy
          flake8 tests/ --format=json --output-file=flake8-tests-report.json || true

      - name: MyPy Type Checking
        run: |
          mypy main.py --strict --junit-xml mypy-report.xml || true
          mypy tests/ --junit-xml mypy-tests-report.xml || true

      - name: Pylint Code Analysis
        run: |
          pylint main.py --output-format=json --output-file=pylint-report.json || true
          pylint main.py --output-format=text

      - name: Upload Quality Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: quality-reports
          path: |
            flake8-report.json
            flake8-tests-report.json
            mypy-report.xml
            mypy-tests-report.xml
            pylint-report.json
          retention-days: 30

  # === MULTI-PLATFORM TESTING ===

  test-matrix:
    name: üß™ Test Matrix
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.11', '3.12', '3.13']
        exclude:
          # Exclude Python 3.13 on Windows for now due to potential compatibility issues
          - os: windows-latest
            python-version: '3.13'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/Library/Caches/pip  # macOS
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ env.CACHE_VERSION }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ env.CACHE_VERSION }}-
            ${{ runner.os }}-pip-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov pytest-xvfb pytest-benchmark
          pip install pytest-mock pytest-asyncio
          pip install -r requirements.txt

      - name: Validate FastMCP 2.0 Compatibility
        run: |
          python -c "
          import fastmcp
          import pkg_resources
          version = pkg_resources.get_distribution('fastmcp').version
          print(f'FastMCP version: {version}')

          # Check for FastMCP 2.0+ features
          if tuple(map(int, version.split('.'))) >= (2, 0, 0):
              print('‚úÖ FastMCP 2.0+ detected')
          else:
              print('‚ùå FastMCP < 2.0 detected')
              exit(1)
          "

      - name: Run Unit Tests with Coverage
        run: |
          pytest tests/ -v --tb=short \
                 --cov=main \
                 --cov=tests \
                 --cov-report=xml:coverage-${{ matrix.os }}-${{ matrix.python-version }}.xml \
                 --cov-report=html:htmlcov-${{ matrix.os }}-${{ matrix.python-version }} \
                 --cov-report=term \
                 --junit-xml=test-results-${{ matrix.os }}-${{ matrix.python-version }}.xml

      - name: Run Integration Tests
        run: |
          pytest tests/integration/ -v --tb=short \
                 --junit-xml=integration-results-${{ matrix.os }}-${{ matrix.python-version }}.xml \
                 -k "not slow"

      - name: Performance Benchmarking
        run: |
          pytest tests/integration/test_load_harness.py -v \
                 --benchmark-only \
                 --benchmark-json=benchmark-${{ matrix.os }}-${{ matrix.python-version }}.json \
                 -k "benchmark" || true

      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            coverage-*.xml
            htmlcov-*/
            test-results-*.xml
            integration-results-*.xml
            benchmark-*.json
          retention-days: 30

  # === SECURITY ISOLATION TESTING (CVE-003-001) ===

  security-isolation:
    name: üõ°Ô∏è Security Isolation Testing
    runs-on: ubuntu-latest
    needs: [security-scan]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-asyncio
          pip install -r requirements.txt

      - name: Run CVE-003-001 Isolation Tests
        run: |
          # Test the specific vulnerability scenarios from CVE-003-001
          pytest tests/test_security_bypass_vulnerability.py -v
          pytest tests/test_critical_vulnerability_demonstration.py -v
          pytest tests/test_realistic_import_blocking.py -v

      - name: Run Security Harness Tests
        run: |
          pytest tests/integration/test_security_harness.py -v

      - name: Simulate Attack Scenarios
        run: |
          python -c "
          import sys
          import main
          print('Testing isolation mechanisms...')

          # Test RestrictedPython isolation
          try:
              # Attempt to break out of sandbox
              test_code = '''
import os
import sys
__import__('subprocess').run(['whoami'], capture_output=True)
'''
              result = main.analyze_symbolic_execution(
                  code=test_code,
                  options={'timeout': 5}
              )
              if 'subprocess' in str(result).lower():
                  print('‚ùå Sandbox escape detected!')
                  sys.exit(1)
              else:
                  print('‚úÖ Sandbox escape blocked')
          except Exception as e:
              print(f'‚úÖ Sandbox properly blocked access: {e}')
          "

      - name: Memory Leak Detection
        run: |
          pytest tests/integration/test_memory_leak_detector.py -v \
                 --timeout=300

      - name: Upload Security Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-isolation-results
          path: |
            tests/pytest.xml
            security-test-logs.txt
          retention-days: 30

  # === PERFORMANCE & STRESS TESTING ===

  performance-testing:
    name: üöÄ Performance Testing
    runs-on: ubuntu-latest
    needs: [test-matrix]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-benchmark memory_profiler
          pip install -r requirements.txt

      - name: Run Load Tests
        run: |
          pytest tests/integration/test_load_harness.py -v \
                 --benchmark-only \
                 --benchmark-json=load-test-results.json

      - name: Memory Profiling
        run: |
          mprof run pytest tests/integration/ -k "memory" --tb=short
          mprof plot --output memory-profile.png || true

      - name: Performance Regression Check
        run: |
          python -c "
          import json
          import sys

          # Load benchmark results and check for regressions
          try:
              with open('load-test-results.json', 'r') as f:
                  data = json.load(f)

              # Check if performance degraded significantly
              benchmarks = data.get('benchmarks', [])
              for bench in benchmarks:
                  if 'time' in bench.get('stats', {}):
                      mean_time = bench['stats']['mean']
                      if mean_time > 5.0:  # 5 second threshold
                          print(f'‚ùå Performance regression detected: {bench[\"name\"]} took {mean_time:.2f}s')
                          sys.exit(1)

              print('‚úÖ Performance regression check passed')
          except Exception as e:
              print(f'‚ö†Ô∏è Could not check performance: {e}')
          "

      - name: Upload Performance Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-reports
          path: |
            load-test-results.json
            memory-profile.png
            mprof_*.dat
          retention-days: 30

  # === BUILD & ARTIFACT CREATION ===

  build-artifacts:
    name: üì¶ Build Artifacts
    runs-on: ubuntu-latest
    needs: [security-scan, code-quality, test-matrix]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build wheel setuptools
          pip install -r requirements.txt

      - name: Create pyproject.toml for building
        run: |
          cat > pyproject.toml << 'EOF'
          [build-system]
          requires = ["setuptools>=45", "wheel"]
          build-backend = "setuptools.build_meta"

          [project]
          name = "symbolic-mcp"
          version = "1.0.0"
          description = "Symbolic execution MCP server with security isolation"
          readme = "README.md"
          license = {text = "MIT"}
          authors = [
              {name = "Symbolic MCP Contributors"}
          ]
          classifiers = [
              "Development Status :: 4 - Beta",
              "Intended Audience :: Developers",
              "License :: OSI Approved :: MIT License",
              "Programming Language :: Python :: 3",
              "Programming Language :: Python :: 3.11",
              "Programming Language :: Python :: 3.12",
              "Programming Language :: Python :: 3.13",
              "Topic :: Security",
              "Topic :: Software Development :: Testing",
          ]
          requires-python = ">=3.11"
          dependencies = [
              "fastmcp>=2.0.0",
              "crosshair-tool>=0.0.70",
              "z3-solver>=4.12.0",
              "icontract>=2.6.0",
              "typing-extensions>=4.0.0",
              "RestrictedPython>=8.1",
              "pydantic>=2.12.0",
              "psutil>=6.0.0",
          ]

          [project.optional-dependencies]
          test = [
              "pytest>=7.0.0",
              "pytest-cov",
              "pytest-benchmark",
              "pytest-asyncio",
          ]
          dev = [
              "black",
              "isort",
              "flake8",
              "mypy",
              "pylint",
              "bandit",
              "safety",
          ]

          [project.scripts]
          symbolic-mcp = "main:main"

          [project.urls]
          Homepage = "https://github.com/jpwoody/symbolic-mcp"
          Repository = "https://github.com/jpwoody/symbolic-mcp"
          Issues = "https://github.com/jpwoody/symbolic-mcp/issues"
          EOF

      - name: Build Distribution
        run: |
          python -m build

      - name: Validate Built Package
        run: |
          # Install the built package and run basic tests
          pip install dist/*.whl
          python -c "import main; print('‚úÖ Package imports successfully')"

      - name: Generate SBOM
        run: |
          pip install cyclonedx-bom
          cyclonedx-py -o sbom.json -i .

      - name: Upload Build Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: python-package
          path: |
            dist/
            sbom.json
          retention-days: 90

  # === RELEASE AUTOMATION ===

  release:
    name: üéâ Automated Release
    runs-on: ubuntu-latest
    needs: [security-isolation, performance-testing, build-artifacts]
    if: github.event_name == 'release'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_DEFAULT_VERSION }}

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: python-package
          path: dist/

      - name: Install publishing dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build twine

      - name: Verify Build
        run: |
          twine check dist/*

      - name: Generate Release Notes
        id: release_notes
        run: |
          # Generate release notes based on commits since last release
          python -c "
          import subprocess
          import re

          # Get commits since last tag
          try:
              last_tag = subprocess.check_output(['git', 'describe', '--tags', '--abbrev=0'],
                                              stderr=subprocess.DEVNULL).decode().strip()
              commits = subprocess.check_output(['git', 'log', f'{last_tag}..HEAD', '--oneline'],
                                              stderr=subprocess.DEVNULL).decode().strip()
          except subprocess.CalledProcessError:
              commits = subprocess.check_output(['git', 'log', '--oneline'],
                                              stderr=subprocess.DEVNULL).decode().strip()

          # Categorize commits
          features = []
          fixes = []
          security = []
          other = []

          for line in commits.split('\n'):
              if 'feat' in line or 'add' in line.lower():
                  features.append(line)
              elif 'fix' in line or 'bug' in line.lower():
                  fixes.append(line)
              elif 'sec' in line.lower() or 'cve' in line.lower():
                  security.append(line)
              else:
                  other.append(line)

          # Generate markdown
          notes = []
          if features:
              notes.append('## üöÄ Features')
              notes.extend([f'- {feat}' for feat in features])

          if security:
              notes.append('## üõ°Ô∏è Security Fixes')
              notes.extend([f'- {fix}' for fix in security])

          if fixes:
              notes.append('## üêõ Bug Fixes')
              notes.extend([f'- {fix}' for fix in fixes])

          if other:
              notes.append('## üîß Other Changes')
              notes.extend([f'- {change}' for change in other[:10]])

          notes.append('## ‚úÖ Quality Assurance')
          notes.append('- All security checks passed')
          notes.append('- Multi-platform testing successful')
          notes.append('- Performance benchmarks within limits')
          notes.append('- FastMCP 2.0 compatibility verified')

          with open('release-notes.md', 'w') as f:
              f.write('\\n'.join(notes))
          "

      - name: Update Release with Notes
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const notes = fs.readFileSync('release-notes.md', 'utf8');

            github.rest.repos.updateRelease({
              owner: context.repo.owner,
              repo: context.repo.repo,
              release_id: context.release.id,
              body: notes
            });

      - name: Publish to PyPI
        if: startsWith(github.ref, 'refs/tags/')
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
        run: |
          twine upload dist/*

      - name: Publish to Test PyPI (for pre-releases)
        if: contains(github.ref, 'rc') || contains(github.ref, 'alpha') || contains(github.ref, 'beta')
        env:
          TWINE_USERNAME: __token__
          TWINE_PASSWORD: ${{ secrets.TEST_PYPI_API_TOKEN }}
          TWINE_REPOSITORY_URL: https://test.pypi.org/legacy/
        run: |
          twine upload --repository testpypi dist/*

  # === FINAL STATUS CHECK ===

  ci-status:
    name: üìä CI Status Summary
    runs-on: ubuntu-latest
    needs: [security-scan, code-quality, test-matrix, security-isolation, build-artifacts]
    if: always()
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: all-artifacts/

      - name: Generate CI Summary
        run: |
          python -c "
          import json
          import os
          from pathlib import Path

          # Check results from all jobs
          results = {}

          # Check security scan
          security_path = Path('all-artifacts/security-reports')
          if security_path.exists():
              bandit_file = security_path / 'bandit-report.json'
              if bandit_file.exists():
                  with open(bandit_file) as f:
                      bandit_data = json.load(f)
                      high_issues = len([r for r in bandit_data.get('results', [])
                                       if r.get('issue_severity') == 'HIGH'])
                      results['security'] = 'PASS' if high_issues == 0 else 'FAIL'
              else:
                  results['security'] = 'PASS'
          else:
              results['security'] = 'UNKNOWN'

          # Check code quality
          quality_path = Path('all-artifacts/quality-reports')
          results['quality'] = 'PASS' if quality_path.exists() else 'UNKNOWN'

          # Check tests
          test_path = Path('all-artifacts')
          test_results = list(test_path.glob('test-results-*/test-results-*.xml'))
          results['tests'] = 'PASS' if len(test_results) > 0 else 'UNKNOWN'

          # Generate summary
          overall_status = 'PASS' if all(v in ['PASS'] for v in results.values()) else 'FAIL'

          summary = f'''
          ## CI/CD Pipeline Summary

          **Overall Status:** {overall_status}

          | Check | Status |
          |-------|--------|
          | Security Scan | {results.get('security', 'UNKNOWN')} |
          | Code Quality | {results.get('quality', 'UNKNOWN')} |
          | Test Matrix | {results.get('tests', 'UNKNOWN')} |

          **Triggered by:** {os.environ.get('GITHUB_EVENT_NAME', 'unknown')}
          **Branch:** {os.environ.get('GITHUB_REF_NAME', 'unknown')}
          **Commit:** {os.environ.get('GITHUB_SHA', 'unknown')[:7]}
          '''

          with open('ci-summary.md', 'w') as f:
              f.write(summary)

          print(summary)
          "

      - name: Comment on PR/Commit
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try:
              const summary = fs.readFileSync('ci-summary.md', 'utf8');

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: summary
              });
            } catch (error) {
              console.log('Could not read CI summary:', error.message);
            }

      - name: Upload CI Summary
        uses: actions/upload-artifact@v4
        with:
          name: ci-summary
          path: ci-summary.md
          retention-days: 30